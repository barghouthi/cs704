\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ...
%\geometry{landscape}                		% Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex
\usepackage{amssymb}
\usepackage{url}
\usepackage{stmaryrd}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\newcommand{\lang}{\mathcal{L}}
\title{Assignment 5}

\begin{document}
\maketitle

\section{Interpolants}

This question concerns the logical notion
of \emph{Craig interpolants}.
You do not require prior knowledge about interpolation
to answer this question.

Given two formulas $A$ and $B$ in first-order logic,
such that $A \land B$ is unsatisfiable,
there exists a formula $I$, called an interpolant, such that
\begin{enumerate}
    \item $A \Rightarrow I$ is valid (recall that a formula $\phi$ is valid iff all models satisfy it)
    \item $I \land B$ is unsatisfiable;
    \item $\emph{vars}(I) \subseteq \emph{vars}(A) \cap \emph{vars}(B)$,
        where $\emph{vars}(\phi)$ is the set of all variables
        that appear in $\phi$.
\end{enumerate}

As an example, consider the following formulas
in propositional logic (i.e., all variables are Boolean):
%
$$A \triangleq a \land b$$
$$B \triangleq \neg b \land c$$
%
We know that $A \land B$ is unsatisfiable.
An interpolant $I$ here is $b$. Observe that
$A \Rightarrow I$ is valid, $I \land  B$ is unsatisfiable,
and $I$ only contains variables that appear in $A$ and $B$.


\subsection{}
An alternative definition of an interpolant
is as follows:

Suppose we have two formulas $A$ and $C$
such that $A \Rightarrow C$ is valid, then
there exists a formula $I$ such that
\begin{enumerate}
    \item $A \Rightarrow I$ is valid;
    \item $I \Rightarrow C$ is valid;
    \item $\emph{vars}(I) \subseteq \emph{vars}(A) \cap \emph{vars}(C)$.
\end{enumerate}

Prove that the two definitions of an interpolant are equivalent.

\subsection{}
Give two formulas $A$ and $B$ such that $A\land B$ is unsatisfiable,
does there always exist a unique interpolant (up to logical equivalence)?
If not, provide an example of two formulas $A$ and $B$ and
two interpolants $I_1$ and $I_2$,
such that $I_1 \neq I_2$.


\subsection{}
Suppose you are working with formulas
in quantifier-free linear integer arithmetic:
meaning, formulas that are Boolean combinations (conjunctions, disjunctions, negations)
of linear inequalities over integers
of the form: $a_1x_1 + \ldots a_nx_n \leq c$,
where $a_i,c$ are integer constants, and $x_i$ are integer
variables.

Consider the following two formulas in quantifier-free
linear integer arithmetic:

$$A \triangleq x = 2y$$
$$B \triangleq x = 2z - 1$$

Is $A \land B$ satisfiable?
If not, does there exist an interpolant
for $A$ and $B$ that is also in quantifier-free linear integer arithmetic?
If no such interpolant exists, explain why that is the case.


\section{Extending Static Analysis to a Probabilistic Setting}

\newcommand{\prog}{\mathcal{L}}
\newcommand{\pprog}{\mathcal{L}^\sim}

\newcommand{\stat}{\mathcal{A}}

Let $\prog$ be a very simple programming language
where a program $P \in \prog$ is comprised of assignment,
conditional, and while-loop statements.
Assume also that all variables are either Boolean or real-valued,
and that all programs of interest are well-typed and exhibit
no runtime errors (e.g., divisions by zero).

For a program $P$, we assume it has  a set of input variables $V_i$
and a set of output variables $V_r$.
For the rest of this question, imagine that we have at our
disposal an almighty static analyzer $\stat$ that, given $P \in \prog$,
returns a set $S$ of all states reachable by executing $P$ from
any possible input.
A state $s \in S$ is considered to be a map from every variable
in $P$ to a value.
Given variable $x$, we use $s[x]$ to denote the value of $x$
in $s$.

\paragraph{Example 1}
For illustration, consider the following example:
%
\begin{verbatim}
def p(x)
  y = x + 1
  return y
\end{verbatim}
%
Given the above program, the static analyzer returns
the set
$$\{s \mid s[x] = c, s[y] = c + 1, c \in \mathbb{R}\}$$
In other words, it returns the set of all states $s$ where $y = x + 1$.

\paragraph{Example 2}
We also assume that our language $\lang$ allows non-deterministic
choice, which is denoted by \texttt{if (*) ... else ...},
where the program can non-deterministically execute either branch of the
conditional statement.
Consider, for example, the following simple program:
\begin{verbatim}
def p()
  if (*)
    y = 1
  else
    y = 2
  return y
\end{verbatim}
Given the above program, the static analyzer returns the set
$$\{ s \mid s[y] \in \{1,2\}\}$$


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Using $\stat$ for probabilistic reasoning}
\label{sec:proba}

Suppose that we decide to extend our language
$\prog$ into a new language $\pprog$ with random assignments of the form
\begin{verbatim}
  x ~ bern(c)
\end{verbatim}
where Boolean variable \texttt{x} is assigned true with probability \texttt{c}
and false with probability \texttt{1-c}, where $\texttt{c}$ is a constant in $ [0,1]$.
(\texttt{bern} stands for a Bernoulli distribution.)

Given a program $P \in \pprog$, we are typically
interested in the probability of the program returning
a specific set of values.
For example, consider the following probabilistic program:
\begin{verbatim}
def p()
  x ~ bern(0.5)
  y ~ bern(0.5)
  z =  x && y
  return z
\end{verbatim}
The probability that \texttt{p} returns true
is 0.25, as both \texttt{x} and \texttt{y} have to be true.

Your task in this question is as follows:
Given a program $P \in \pprog$ and the static
analyzer $\stat$, you are to use $\stat$
to compute the probability that $P$ returns
a value in some set $X$.
Note that $\stat$ only accepts programs in $\prog$,
so you have to somehow transform $P \in \pprog$ into a new
program in $\prog$
in order to be able to use $\stat$.
Once you have the output set $S$ of $\stat$,
you may apply any mathematical  operation on $S$ to
extract your desired result.

You should assume that $P$ is always terminating,
has no non-deterministic conditionals,
has no input variables (like the above example),
and only manipulates Boolean variables.
\textbf{Hint:} your transformation of $P$
may introduce non-determinism, real-valued variables,
and lists.

\subsection{Discovering maximizing inputs}
In the first part of the question,
we assumed that $P$ has no input variables.
In this part, we will assume that $P$ has input variables.
Our goal is to find a value for the input variables
that maximizes the probability of returning some output value.
Consider the following example:
\begin{verbatim}
def p(x)
  if (x)
    y ~ bern(0.5)
  else
    y ~ bern(0.9)
  return y
\end{verbatim}
Suppose we want to maximize the probability
that \texttt{p} returns the value true.
To do so, we have to set the input variable \texttt{x}
to false in order to force the program down the
else branch of \texttt{p}, which has a higher
probability of setting \texttt{y} to true.

Describe how you would extend your
technique from Part~\ref{sec:proba} to this setting.

\section{Galois connections}
Consider these two definitions of Galois connections:

\paragraph{Definition 1:}
$(L,\alpha,\gamma,M)$ is a Galois connection
between the complete lattices $(L,\sqsubseteq)$
and $(M,\sqsubseteq)$ if and only if
$\alpha:L \rightarrow M$ and $\gamma:M \rightarrow L$
are monotone functions that satisfy the following conditions:
$$\textrm{forall } l \in L \ldotp \gamma(\alpha(l)) \sqsupseteq l$$
$$\textrm{forall } m \in M \ldotp \alpha(\gamma(m)) \sqsubseteq m$$
where $\circ$ is function composition---that is,
$\alpha \circ \gamma$ is the function that applies
$\alpha$ \emph{to the result of} $\gamma$.

\paragraph{Definition 2:}
$(L,\alpha,\gamma,M)$ is a Galois connection
between the complete lattices $(L,\sqsubseteq)$
and $(M,\sqsubseteq)$ if and only if
$\alpha:L \rightarrow M$ and $\gamma:M \rightarrow L$
are total functions such that for all $l\in L, m \in M$,
$$\alpha(l) \sqsubseteq m \Leftrightarrow l \sqsubseteq \gamma (m)$$

~\\
Prove that the two definitions are equivalent.

\end{document}
